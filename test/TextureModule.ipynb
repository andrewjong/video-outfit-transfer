{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all Jupyter output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TextureDataset\n",
    "\n",
    "from src.datasets import TextureDataset\n",
    "\n",
    "texture_dir = \"../data/andrew/texture\"\n",
    "cloth_dir = \"../data/andrew/clothing\"\n",
    "rois_db = \"../data/andrew/rois.csv\"\n",
    "\n",
    "\n",
    "CROP_BOUNDS = (\n",
    "    (160, 672),  # HEIGHT (determined by looking at sample frames. want to get the head)\n",
    "    (14, 526),  # WIDTH (calculated by (540 - 512)/2, then centered  )\n",
    ")\n",
    "\n",
    "texture_dataset = TextureDataset(\n",
    "    texture_dir, rois_db, cloth_dir, crop_bounds=CROP_BOUNDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(texture_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.texture_module import TextureModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TextureModule(texture_channels=3, dropout=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 512, 512]),\n",
       " torch.Size([2, 6, 5]),\n",
       " torch.Size([2, 3, 512, 512]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape, x[1].shape, x[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/remoteuser/faster-rcnn.pytorch/lib\")\n",
    "from model.roi_layers import ROIAlign\n",
    "from src.nets import UNetDown, UNetUp\n",
    "channels=3\n",
    "dropout=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROI = 6\n",
    "class TextureModule(nn.Module):\n",
    "    def __init__(self, texture_channels=3, dropout=0.5):\n",
    "        super(TextureModule, self).__init__()\n",
    "        self.roi_align = ROIAlign(\n",
    "            output_size=(128, 128), spatial_scale=1, sampling_ratio=1\n",
    "        )\n",
    "\n",
    "        channels = texture_channels * NUM_ROI\n",
    "        self.encode = UNetDown(channels, channels)\n",
    "\n",
    "        # UNET\n",
    "        self.down_1 = UNetDown(channels + texture_channels, 64, normalize=False)\n",
    "        self.down_2 = UNetDown(64, 128)\n",
    "        self.down_3 = UNetDown(128, 256)\n",
    "        self.down_4 = UNetDown(256, 512, dropout=dropout)\n",
    "        self.down_5 = UNetDown(512, 1024, dropout=dropout)\n",
    "        self.down_6 = UNetDown(1024, 1024, normalize=False, dropout=dropout)\n",
    "        self.up_1 = UNetUp(1024, 1024, dropout=dropout)\n",
    "        self.up_2 = UNetUp(2 * 1024, 512, dropout=dropout)\n",
    "        self.up_3 = UNetUp(2 * 512, 256)\n",
    "        self.up_4 = UNetUp(2 * 256, 128)\n",
    "        self.up_5 = UNetUp(2 * 128, 64)\n",
    "\n",
    "        self.upsample_and_pad = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, texture_channels, 4, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = TextureModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tex = x[0]\n",
    "rois = x[1]\n",
    "cloth = x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois = rois.view(-1, 5)\n",
    "rois[:, 0] = rois[:, 0] - rois[0, 0]\n",
    "rois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_rois = self.roi_align(input_tex, rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = pooled_rois.shape[0] / NUM_ROI\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 128, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_rois = pooled_rois.view(int(bs), -1, pooled_rois.shape[2], pooled_rois.shape[3])\n",
    "pooled_rois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tex = self.encode(pooled_rois)\n",
    "encoded_tex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = input_tex.shape[2] / encoded_tex.shape[2]\n",
    "scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 512, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "upsampled_tex = nn.functional.interpolate(encoded_tex, scale_factor=scale_factor)\n",
    "upsampled_tex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 21, 512, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex_with_cloth = torch.cat((upsampled_tex, cloth), 1)\n",
    "tex_with_cloth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 256, 256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = self.down_1(tex_with_cloth)\n",
    "d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 128, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = self.down_2(d1)\n",
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 64, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 32, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 16, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048, 16, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 32, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 64, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 128, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 256, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = self.down_3(d2)\n",
    "d3.shape\n",
    "d4 = self.down_4(d3)\n",
    "d4.shape\n",
    "d5 = self.down_5(d4)\n",
    "d5.shape\n",
    "d6 = self.down_6(d5)\n",
    "d6.shape\n",
    "u1 = self.up_1(d6, d5)\n",
    "u1.shape\n",
    "u2 = self.up_2(u1, d4)\n",
    "u2.shape\n",
    "u3 = self.up_3(u2, d3)\n",
    "u3.shape\n",
    "u4 = self.up_4(u3, d2)\n",
    "u4.shape\n",
    "u5 = self.up_5(u4, d1)\n",
    "u5.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remoteuser/.miniconda3/envs/compile-faster-rcnn/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "us = self.upsample_and_pad(u5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
